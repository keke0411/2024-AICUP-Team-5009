{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo for AICUP\n",
    "\n",
    "Here is our demo code. We have already set all parameter and path up, thus you only need to run all to get demo results and txt files in `results/detect/`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import time\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "from tqdm import tqdm\n",
    "from numpy import random\n",
    "\n",
    "sys.path.insert(0, './yolov7')\n",
    "sys.path.append('.')\n",
    "\n",
    "from yolov7.models.experimental import attempt_load\n",
    "from yolov7.utils.datasets import LoadStreams, LoadImages\n",
    "from yolov7.utils.general import check_img_size, check_requirements, check_imshow, non_max_suppression, \\\n",
    "    apply_classifier, \\\n",
    "    scale_coords, xyxy2xywh, strip_optimizer, set_logging, increment_path\n",
    "from yolov7.utils.plots import plot_one_box\n",
    "from yolov7.utils.torch_utils import select_device, load_classifier, time_synchronized, TracedModel\n",
    "\n",
    "from tracker.mc_bot_sort import BoTSORT\n",
    "from tracker.tracking_utils.timer import Timer\n",
    "\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference parameters settings\n",
    "\n",
    "- The default settings are our inference settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can modify the path if needed\n",
    "ReID_path = r\"results/ReID/model_0058.pth\"  # trained ReID weights path\n",
    "Yolov7_path = 'results/Yolov7/best.pt'  # trained YOLOv7 weights path\n",
    "save_path = 'results/detect'  # save path\n",
    "test_dir = 'AI_CUP_testdata/images/'  # test directory path\n",
    "timestamp = '0902_130006_131041'  # test data timestamp\n",
    "test_path = test_dir + timestamp  # test data path\n",
    "\n",
    "class Opt:\n",
    "    def __init__(self):\n",
    "        self.weights = [Yolov7_path]\n",
    "        self.source = test_path  # file/folder, 0 for webcam\n",
    "        self.img_size = 1920\n",
    "        self.conf_thres = 0.09\n",
    "        self.iou_thres = 0.7\n",
    "        self.device = '0'\n",
    "        self.view_img = False\n",
    "        self.save_txt = False\n",
    "        self.save_conf = False\n",
    "        self.nosave = False\n",
    "        self.classes = None\n",
    "        self.agnostic_nms = False\n",
    "        self.augment = False\n",
    "        self.update = False\n",
    "        self.project = save_path\n",
    "        self.name = 'exp'  # save name\n",
    "        self.exist_ok = False\n",
    "        self.trace = False\n",
    "        self.hide_labels_name = False\n",
    "\n",
    "        # tracking args\n",
    "        self.track_high_thresh = 0.3\n",
    "        self.track_low_thresh = 0.05\n",
    "        self.new_track_thresh = 0.4\n",
    "        self.track_buffer = 30\n",
    "        self.match_thresh = 0.7\n",
    "        self.aspect_ratio_thresh = 1.6\n",
    "        self.min_box_area = 10\n",
    "        self.mot20 = False  # fuse_score\n",
    "\n",
    "        # CMC\n",
    "        self.cmc_method = \"sparseOptFlow\"\n",
    "\n",
    "        # ReID\n",
    "        self.with_reid = False,\n",
    "        self.fast_reid_config = r\"fast_reid/configs/AICUP/bagtricks_R50-ibn.yml\"\n",
    "        self.fast_reid_weights = ReID_path\n",
    "        self.proximity_thresh = 0.5\n",
    "        self.appearance_thresh = 0.25\n",
    "\n",
    "        self.jde = False\n",
    "        self.ablation = False\n",
    "    \n",
    "    def set_source(self, source):\n",
    "        self.source = source\n",
    "\n",
    "    def set_name(self, name):\n",
    "        self.name = name\n",
    "\n",
    "opt = Opt()\n",
    "\n",
    "for k, v in vars(opt).items():\n",
    "    print(f\"{k}: {v}\")\n",
    "# check_requirements(exclude=('pycocotools', 'thop'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect funtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(save_img=False):\n",
    "    source, weights, view_img, save_txt, imgsz, trace = opt.source, opt.weights, opt.view_img, opt.save_txt, opt.img_size, opt.trace\n",
    "    save_img = not opt.nosave and not source.endswith('.txt')  # save inference images\n",
    "    print(f\"source: {source}\")\n",
    "    print(f\"source.isnumeric(): {source.isnumeric()}\")\n",
    "    webcam = source.isnumeric() or source.endswith('.txt') or source.lower().startswith(\n",
    "        ('rtsp://', 'rtmp://', 'http://', 'https://'))\n",
    "\n",
    "    # Directories\n",
    "    save_dir = Path(increment_path(Path(opt.project) / opt.name, exist_ok=opt.exist_ok))  # increment run\n",
    "    (save_dir / 'labels' if save_txt else save_dir).mkdir(parents=True, exist_ok=True)  # make dir\n",
    "\n",
    "    # Initialize\n",
    "    set_logging()\n",
    "    device = select_device(opt.device)\n",
    "    half = device.type != 'cpu'  # half precision only supported on CUDA\n",
    "\n",
    "    # Load model\n",
    "    model = attempt_load(weights, map_location=device)  # load FP32 model\n",
    "    stride = int(model.stride.max())  # model stride\n",
    "    imgsz = check_img_size(imgsz, s=stride)  # check img_size\n",
    "\n",
    "    if trace:\n",
    "        model = TracedModel(model, device, opt.img_size)\n",
    "\n",
    "    if half:\n",
    "        model.half()  # to FP16\n",
    "\n",
    "    # Second-stage classifier\n",
    "    classify = False\n",
    "    if classify:\n",
    "        modelc = load_classifier(name='resnet101', n=2)  # initialize\n",
    "        modelc.load_state_dict(torch.load('weights/resnet101.pt', map_location=device)['model']).to(device).eval()\n",
    "\n",
    "    # Set Dataloader\n",
    "    vid_path, vid_writer = None, None\n",
    "    if webcam:\n",
    "        view_img = check_imshow()\n",
    "        cudnn.benchmark = True  # set True to speed up constant image size inference\n",
    "        dataset = LoadStreams(source, img_size=imgsz, stride=stride)\n",
    "    else:\n",
    "        dataset = LoadImages(source, img_size=imgsz, stride=stride)\n",
    "\n",
    "    # Get names and colors\n",
    "    names = model.module.names if hasattr(model, 'module') else model.names\n",
    "    colors = [[random.randint(0, 255) for _ in range(3)] for _ in range(100)]\n",
    "\n",
    "    # Create tracker\n",
    "    tracker = BoTSORT(opt, frame_rate=30.0)\n",
    "\n",
    "    # Run inference\n",
    "    if device.type != 'cpu':\n",
    "        model(torch.zeros(1, 3, imgsz, imgsz).to(device).type_as(next(model.parameters())))  # run once\n",
    "        \n",
    "    t0 = time.time()\n",
    "    \n",
    "    # Process detections\n",
    "    results = []\n",
    "    frameID = 0\n",
    "\n",
    "    for path, img, im0s, vid_cap in tqdm(dataset, desc=f'tracking {opt.name}'):\n",
    "        frameID += 1\n",
    "        img = torch.from_numpy(img).to(device)\n",
    "        img = img.half() if half else img.float()  # uint8 to fp16/32\n",
    "        img /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
    "        if img.ndimension() == 3:\n",
    "            img = img.unsqueeze(0)\n",
    "\n",
    "        # Inference\n",
    "        t1 = time_synchronized()\n",
    "        pred = model(img, augment=opt.augment)[0]\n",
    "\n",
    "        # Apply NMS\n",
    "        pred = non_max_suppression(pred, opt.conf_thres, opt.iou_thres, classes=opt.classes, agnostic=opt.agnostic_nms)\n",
    "        t2 = time_synchronized()\n",
    "\n",
    "        # Apply Classifier\n",
    "        if classify:\n",
    "            pred = apply_classifier(pred, modelc, img, im0s)\n",
    "\n",
    "        for i, det in enumerate(pred):  # detections per image\n",
    "            if webcam:  # batch_size >= 1\n",
    "                p, s, im0, frame = path[i], '%g: ' % i, im0s[i].copy(), dataset.count\n",
    "            else:\n",
    "                p, s, im0, frame = path, '', im0s, getattr(dataset, 'frame', 0)\n",
    "\n",
    "            # Run tracker\n",
    "            detections = []\n",
    "            if len(det):\n",
    "                boxes = scale_coords(img.shape[2:], det[:, :4], im0.shape)\n",
    "                boxes = boxes.cpu().numpy()\n",
    "                detections = det.cpu().numpy()\n",
    "                detections[:, :4] = boxes\n",
    "\n",
    "            online_targets = tracker.update(detections, im0, frameID)\n",
    "\n",
    "            online_tlwhs = []\n",
    "            online_ids = []\n",
    "            online_scores = []\n",
    "            online_cls = []\n",
    "            for t in online_targets:\n",
    "                tlwh = t.tlwh\n",
    "                tlbr = t.tlbr\n",
    "                tid = t.track_id\n",
    "                tcls = t.cls\n",
    "                if tlwh[2] * tlwh[3] > opt.min_box_area:\n",
    "                    online_tlwhs.append(tlwh)\n",
    "                    online_ids.append(tid)\n",
    "                    online_scores.append(t.score)\n",
    "                    online_cls.append(t.cls)\n",
    "\n",
    "                    if save_img or view_img:  # Add bbox to image\n",
    "                        if opt.hide_labels_name:\n",
    "                            label = f'{tid}, {int(tcls)}'\n",
    "                        else:\n",
    "                            label = f'{tid}, {names[int(tcls)]}'\n",
    "                        \n",
    "                        if 'car' in label: # AICUP only have one cls: car\n",
    "                            # save results\n",
    "                            results.append(\n",
    "                                f\"{frameID},{tid},{tlwh[0]:.2f},{tlwh[1]:.2f},{tlwh[2]:.2f},{tlwh[3]:.2f},{t.score:.2f},-1,-1,-1\\n\"\n",
    "                            )\n",
    "\n",
    "                            plot_one_box(tlbr, im0, label=label, color=colors[int(tid) % len(colors)], line_thickness=2)\n",
    "\n",
    "                            \n",
    "            p = Path(p)  # to Path\n",
    "            save_path = str(save_dir / p.name)  # img.jpg\n",
    "\n",
    "            # Print time (inference + NMS)\n",
    "            # print(f'{s}Done. ({t2 - t1:.3f}s)')\n",
    "\n",
    "            # Stream results\n",
    "            if view_img:\n",
    "                cv2.imshow('BoT-SORT', im0)\n",
    "                cv2.waitKey(1)  # 1 millisecond\n",
    "\n",
    "            # Save results (image with detections)\n",
    "            if save_img:\n",
    "                if dataset.mode == 'image':\n",
    "                    cv2.imwrite(save_path, im0)\n",
    "                else:  # 'video' or 'stream'\n",
    "                    if vid_path != save_path:  # new video\n",
    "                        vid_path = save_path\n",
    "                        if isinstance(vid_writer, cv2.VideoWriter):\n",
    "                            vid_writer.release()  # release previous video writer\n",
    "                        if vid_cap:  # video\n",
    "                            fps = vid_cap.get(cv2.CAP_PROP_FPS)\n",
    "                            w = int(vid_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "                            h = int(vid_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "                        else:  # stream\n",
    "                            fps, w, h = 30, im0.shape[1], im0.shape[0]\n",
    "                            save_path += '.mp4'\n",
    "                        vid_writer = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))\n",
    "                    vid_writer.write(im0)\n",
    "\n",
    "    if save_txt or save_img:\n",
    "        with open(save_dir / f\"{opt.name}.txt\", 'w') as f:\n",
    "            f.writelines(results)\n",
    "            \n",
    "        print(f\"Results saved to {save_dir}\")\n",
    "\n",
    "    print(f'Done. ({time.time() - t0:.3f}s)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference part\n",
    "\n",
    "- Here we run the inference once for all timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    with torch.no_grad():\n",
    "        for source in glob.glob(test_dir + '/*'):\n",
    "            opt.set_source(source)\n",
    "            opt.set_name(source.split('/')[-1])\n",
    "            if opt.update:  # update all models (to fix SourceChangeWarning)\n",
    "                for opt.weights in ['yolov7.pt']:\n",
    "                    detect()\n",
    "                    strip_optimizer(opt.weights)\n",
    "            else:\n",
    "                detect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PadFinal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
